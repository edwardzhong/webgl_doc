
## WebGL 高级技术

### 如何实现选中物体

1. 鼠标按下时物体重绘为红色或其他能区分的颜色

2. 读取鼠标点击处像素的颜色

   ```javascript
   gl.readPixels(x,y,width,height,format,type,pixels)
   ```

3. 使用物体原来的颜色进行重绘，以恢复物体本来颜色

4. 判断第2步读取到的颜色是否与预设的颜色值相等，相等则表示点击中物体



### 如何实现雾化

实现雾化的方式由多种，这里使用最简单的一种：线性雾化 linear fog。在线性雾化中，某一点的雾化程度取决于它与视点之间的距离，距离越远雾化程度越高。线性雾化有起点和终点，起点表示开始雾化之处，终点表示完全雾化之处两点之间某一点的雾化程度与该点与视点的距离呈线性关系。比终点更远的点完全雾化了，即完全看不见了。

```c
//某一点雾化的程度可以被定义为雾化因子 fog factor，并在线性雾化公式中被计算出来：
<雾化因子> = (<终点> - <当前点与视点间的距离>) / (<终点> - <起点>)

//雾化因子为1.0，表示该点完全没有被雾化，可以很清晰地看到此处的物体。如果为0.0, 就表示改点完全被雾化
<起点> <= <当前点与视点间的距离> <= <终点>

//片元着色器中包含雾化因子的片元颜色计算公式
<片元颜色> = <物体表面颜色> * <雾化因子> + <雾化颜色> * (1 - <雾化因子>)
```



#### 使用顶点的w分量作为当前点与视点间的距离

之前，我们并未显式使用过gl_Position的w分量，实际上，这个w分量的值就是顶点的视图坐标的z分量乘以-1。在视图坐标系中，视点在原点，视线沿着Z轴负方向，观察者看到的物体其视图坐标系值z分量都是负的，而gl_Position的w分量正好是z分量值乘以-1，所以可以直接使用该值来近似顶点和视点间的距离。



### 绘制圆形的点

为了将矩形削成圆形，需要知道每个片元在光栅化过程中的坐标。在第5章的一个示例程序中，在片元着色器中通过内置变量gl_FragCoord来访问片元的坐标。实际上，片元着色器还提供了另外一个内置变量gl_PointCoord。这个变量可以帮助我们绘制圆形的点。片元着色器内置变量：

```c
 vec4 gl_FragCoord//片元在窗口坐标
 vec4 gl_PointCoord//片元在被绘制的点内的坐标 从0.0到1.0

 //gl_PointCoord坐标值的区间从0.0到1.0，为了将矩形削成圆形，需要将与中心点 0.5, 0.5距离超过0.5,也就是将圆外的片元剔除掉。在片元着色器中，可以使用discard语句来放弃当前片元。
 //在片元着色器中的代码实现方式如下：

 #ifdef GL_ES
 precision mediump float;
 #endif
 void main(){
     float distance = distance(gl_PointCoord, vec2(0.5, 0.5));
     if (distance <= 0.5){
         gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
     } else {
         discard;
     }
 }
```



### 功能设置和查询 

gl.enable(cap) 启用

gl.disable(cap) 关闭

gl.isEnabled(cap) 是否启用

功能(capability)包含如下：

| 功能                             | 描述                                        |
| -------------------------------- | ------------------------------------------- |
| gl.CULL_FACE                     | 启用面剔除                                  |
| gl.POLYGON_OFFSET_FILL           | 偏移片段深度值                              |
| gl.SCISSOR_TEST                  | 进一步限制渲染限制在剪切矩形中              |
| gl.SAMPLE_COVERAGE               | 在多重采样操作中使用片段的已计算范围值      |
| gl.SAMPLE_ALPHA_TO_COVERAGE      | 在多重采样操作中使用片段的Alpha值做为范围值 |
| gl.STENCIL_TEST                  | 启用模版测试                                |
| gl.DEPTH_TEST                    | 启用深度测试                                |
| gl.BLEND                         | 启用混合                                    |
| gl.PRIMITIVE_RESTART_FIXED_INDEX | 启用图元重启                                |
| gl.RASTERIZER_DISCARD            | 光栅化之前启用图元抛弃                      |
| gl.DITHER                        | 启用抖动                                    |



### α混合

让物体实现半透明效果需要用到颜色的α分量。该功能被称为a混合(alpha blending) 或 混合 blending，WebGL已经内置该功能，但需要开启，如果只设置了颜色的第四个分量α是看不到透明效果的，必须要执行下面两个步骤:

1. 开启混合功能：gl.enable(gl.BLEND)。
2. 指定混合函数：gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA)。



#### gl.blendFunc(src_factor, dst_factor)

a混合函数，参数：

* src_factor: 指定源颜色在混合颜色的权重因子，如下表所示
* dst_factor: 指定目标颜色在混合后颜色的权重因子，如下表所示

```c
// 混合颜色计算公式： 
<混合后的颜色> = <源颜色> * src_factor + <目标颜色> * dst_factor

// 一般半透明效果常用如下形式
gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA)
```

#### 权重因子列表

| 常量                          | 值                                  |
| :---------------------------- | :---------------------------------- |
| GL_ZERO                     | 因子等于0                           |
| GL_ONE                      | 因子等于1                           |
| GL_SRC_COLOR                | 因子等于源颜色向量C source          |
| GL_ONE_MINUS_SRC_COLOR      | 因子等于1− C source                 |
| GL_DST_COLOR                | 因子等于目标颜色向量C destination   |
| GL_ONE_MINUS_DST_COLOR      | 因子等于1− C destination            |
| GL_SRC_ALPHA                | 因子等于C source 的alpha分量        |
| GL_ONE_MINUS_SRC_ALPHA      | 因子等于1− C source 的alpha分量     |
| GL_DST_ALPHA                | 因子等于C destination的alpha分量    |
| GL_ONE_MINUS_DST_ALPHA      | 因子等于1− C destination的alpha分量 |
| GL_CONSTANT_COLOR           | 因子等于常数颜色向量C constant      |
| GL_ONE_MINUS_CONSTANT_COLOR | 因子等于1−C constant                |
| GL_CONSTANT_ALPHA           | 因子等于C constant 的 alpha分量     |
| GL_ONE_MINUS_CONSTANT_ALPHA | 因子等于1− C constant 的 alpha分量  |

#### gl.blendFuncSeprate(src_factor, dst_factor,src_alpha, dst_alpha)

分开指定 rgb 和 alpha 分量

#### 透明和不透明物体共存

实现 a 混合最简单的方式是屏蔽掉隐藏面消除功能，即去掉 gl.enable(gl.DEPTH_TEST)，但关闭隐藏面消除功能是一个粗暴的解决方案，并不能满足实际需求。其实可通过某些机制，同时实现隐藏面消除和半透明效果，步骤如下：

```c
//1.开启隐藏面消除功能:
gl.enable(gl.DEPTH_TEST)。

//2.绘制所有不透明的物体(a == 1.0)

//3.锁定深度缓冲区的写入操作，使之只读 (深度缓冲区用于隐藏面消除):
gl.depthMask(false);

//4.绘制所有半透明的物体 a < 1.0，注意将物体按深度(距离)排序，从观察者视角获取物体的距离,从远到近绘制

//5.释放深度缓冲区，使之可读可写: 
gl.depthMask(true)
```



### 深度测试

WebGL提供了隐藏面消除（hidden surface removal）功能。这个功能会帮助我们消除那些被遮挡的表面（隐藏面），你可以放心地绘制场景而不必估计个物体在缓冲区中的顺序。开启隐藏面消除功能步骤如下：

```c
// 1. 开启隐藏面消除功能
gl.enable(gl.DEPTH_TEST);

// 2. 在绘制之前，清除深度缓冲区
gl.clear(gl.DEPTH_BUFFER_BIT);

//在清理深度缓冲区的同时还要清理颜色缓冲区，所有可以用按位或（|）连接gl.DEPTH_BUFFER_BIT和gl.COLOR_BUFFER_BIT:
gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
```



#### gl.depthMask(mask)

锁定或释放深度缓冲区写入操作

mask:  锁定深度缓冲区的写入操作 false，释放 true



#### 深度测试函数

gl.depthFunc(gl.LESS);

这个函数接受下面表格中的比较运算符：

| 函数        | 描述                                         |
| :---------- | :------------------------------------------- |
| gl.ALWAYS   | 永远通过深度测试                             |
| gl.NEVER    | 永远不通过深度测试                           |
| gl.LESS     | 在片段深度值小于缓冲的深度值时通过测试       |
| gl.EQUAL    | 在片段深度值等于缓冲区的深度值时通过测试     |
| gl.LEQUAL   | 在片段深度值小于等于缓冲区的深度值时通过测试 |
| gl.GREATER  | 在片段深度值大于缓冲区的深度值时通过测试     |
| gl.NOTEQUAL | 在片段深度值不等于缓冲区的深度值时通过测试   |
| gl.GEQUAL   | 在片段深度值大于等于缓冲区的深度值时通过测试 |

默认情况下使用的深度函数是gl.LESS，它将会丢弃深度值大于等于当前深度缓冲值的所有片段。



### 剔除面

WebGL中的三角形有正反面的概念，默认正面三角形的顶点组绕顺序是逆时针方向(CCW)， 反面三角形是顺时针方向(CW)。开启这个特性后WebGL默认"剔除"背面三角形， "剔除"在这里是"不绘制"的意思。

对于WebGL而言，一个三角形是顺时针还是逆时针是根据裁剪空间中的顶点顺序判断的，这就意味着如果你把一个顺时针的三角形沿 X 轴缩放 -1 ，它将会变成逆时针，或者将逆时针的三角形旋转180度后变成顺时针。而这就是WebGL判断三角形是否处于正反面的原理。

```c
//可剔除的面
gl.FRONT
gl.BACK
gl.FRONT_AND_BACK

//WebGL开启面剔除功能，默认剔除背面
gl.enable(gl.CULL_FACE);

gl.frontFace(gl.CW);//指定顺时针为正面
gl.frontFace(gl.CCW);//指定逆时针组绕的三角形是正面三角形

//剔除正反面
gl.cullFace(gl.FRONT_AND_BACK);
```



### 深度冲突（Z fighting）

当几何图形或物体的两个表面极为接近时，使得表面看上去斑斑驳驳的。这种现象被称为深度冲突。

WebGL提供一种被称为多边形偏移（polygon offset）机制解决这个问题。该机制自动在Z值加上一个偏移量。启动该机制只需要两行代码：

```c
// 1.启动多边形编译
gl.enable(gl.POLYGON_OFFSET_FILL);

// 2.在绘制之前指定用来计算偏移量的参数
gl.polygonOffset(1.0, 1.0);
```

gl.polygonOffset(factor, units)

指定加到每个顶点绘制后的Z值上的偏移量，偏移量按照公式"m \* factor+r \* units"计算，
其中m表示顶点所在表面相对于观察者的视线的角度，
而r表示硬件能够区分两个z值之差的最小值。



### 退化三角形

当三角形带之间不连续，存在跳转的解决办法就是插入额外索引(drawElements) 或插入额外顶点(drawArrays)，这样就得到退化三角形。退化三角形是指至少有两个索引(顶点)相同的，存在面积为0的三角形。这种很容易被GPU检测并删除。

连接两个三角形带需要额外索引的数量取决于第一个三角形带所使用的索引数。

- 如果包含偶数个三角形，则需要增加两个额外索引(第一个三角形带最后一个索引，第二个三角形带第一个索引)
- 如果包含奇数个三角形，则需要增加三个额外索引(第一个三角形带最后两个索引，第二个三角形带第一个索引)





### 读取像素值 

gl.readPixels(x, y, width, height, format, type, pixels)

从颜色缓冲区中读取由x、y、width、height参数确定的矩形块中的所有像素值，并保存在pixels指定的数组中。

```c
gl.readPixels(x, y, width, height, format, type, pixels) 参数：

x,y: //指定颜色缓冲区中矩形块左上角的坐标，同时也是读取的第一个像素的坐标
width，height: //指定矩形块的宽度和高度，以像素为单位
format: //指定像素值颜色格式，必须为gl.RGBA
type: //指定像素值的数据格式，必须为gl.UNSIGNED_BYTE
pixels: //指定用来接收像素数据的Uint8Array类型化数组

//读取的x,y的原点是从左下角开始，而不是从左上角开始。加入canvas长、宽分别为100、30，那么右下角的坐标为(100, 0)。
```



### 清空绘图区

缓冲区包括：

- gl.COLOR_BUFFER_BIT颜色缓冲区
- gl.DEPTH_BUFFER_BIT深度缓冲区
- gl.STENCIL_BUFFER_BIT模板缓冲区。

清理函数分别为

- gl.clearColor(red,green,blue,alpha)
- gl.clearDepth(depth)
- gl.clearStencil(s)。

```c
//设置背景色。openGL的颜色取值返回是0-1。
gl.clearColor(red, green, blue, alpha) 

//用clearColor指定的背景色清空绘图区域。清理绘图区域实际上在清理颜色缓冲区（color buffer），传递的gl.COLOR_BUFFER_BIT就是在告诉WebGL清理颜色缓冲区。
gl.clear(gl.COLOR_BUFFER_BIT) 

//可以用位or(|)指定多个缓冲区
gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
```



### 设置绘图区域

gl.viewport(x, y, width, height)
设置 gl.drawArrays() 和 gl.drawElements()函数的绘图区域。参数：

- x,y:指定绘图区域的左上角，以像素为单位
- width,height：指定绘图区域的宽度和高度



### 画布大小

canvas.clientHeight 和 canvas.clientWidth

大多数程序在画布大小改变时都会保持canvas.width 和 canvas.height 与 canvas.clientWidth 和 canvas.clientHeight 一致，因为他们希望屏幕一像素对应绘制一像素。

但那并不是唯一的选择，也就是说在大多数情况下正确的做法是用canvas.clientHeight 和 canvas.clientWidth来计算长宽比



### 帧缓冲区

#### Canvas 本身就是一个纹理

浏览器使用的画布背后，它们创建了一个颜色纹理， 一个深度缓冲，一个帧缓冲，然后绑定到当前的帧缓冲， 当你调用你的渲染方法时就会绘制到那个纹理上， 然后再用那个纹理将画布渲染到网页中。

#### 渲染到纹理的原理

默认情况下，webgl 在颜色缓冲区绘图，使用隐藏面消除的话，还会用到深度缓冲区。总之绘制的图像结果是存储在颜色缓冲区的。即正常绘制的情况下包含：

* 颜色缓冲区
* 深度缓冲区

WebGL可以把渲染的三维图形作为纹理贴到另一个三维物体上去，要实现这个功能，需要用到帧缓冲区对象。

帧缓冲区对象 framebuffer object可以用来代替颜色缓冲区或深度缓冲区。绘制在帧缓冲区中的对象并不会直接显示canvas上，可以先对帧缓冲区中的内容进行一些处理再显示，或者直接用其中的内容作为纹理图像。在帧缓冲区中进行绘制的过程又称为离屏绘制 offscreen drawing。

绘制操作并不是直接发生在帧缓冲区中，而是发生在帧缓冲区所关联的对象 attachment上，一个帧缓冲区有3个关联对象：

* 颜色关联对象 color attachment，对应颜色缓冲区
* 深度关联对象 depth attachment，对应深度缓冲区
* 模板关联对象 stencil attachment，对应模板缓冲区。

每个关联对象可以是如下两种类型之一：

* 纹理对象 texture object

* 渲染缓冲区对象 renderbuffer object。

把纹理对象作为颜色关联对象，并关联到帧缓冲对象后，就可以在纹理对象中绘图

#### Z缓冲区

OpenGL存储它的所有深度信息于Z缓冲区(Z-buffer)中，也被称为深度缓冲区(Depth Buffer)。GLFW会自动为你生成这样一个缓冲区 (就如它有一个颜色缓冲区来存储输出图像的颜色)。深度存储在每个片段里面(作为片段的z值)当片段像输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较然后如果当前的片段在其它片段之后它将会被丢弃，然后重写。这个过程称为**深度测试(Depth Testing)**并且它是由OpenGL自动完成的。

#### 渲染到纹理，帧缓冲区配置步骤

1. 创建帧缓冲区对象 gl.createFramebffer()。
2. 创建文理对象并设置其尺寸和参数 gl.createTexture()、gl.bindTexture()、gl.texImage2D()、gl.Parameteri()。
3. 创建渲染缓冲区对象 gl.createRenderbuffer().
4. 绑定渲染缓冲区对象并设置其尺寸 gl.bindRenderBuffer()、gl.renderbufferStorage()。
5. 将帧缓冲区的颜色关联对象指定为一个文理对象 gl.frambufferTexture2D()。
6. 将帧缓冲区的深度关联对象指定为一个渲染缓冲区对象 gl.framebufferRenderbuffer()。
7. 检查帧缓冲区是否正确配置 gl.checkFramebufferStatus()。
8. 在帧缓冲区中进行绘制 gl.bindFramebuffer()。



#### gl.createRenderbuffer()

创建渲染缓冲区对象

#### deleteRenderbuffer(renderbuffer)

删除渲染缓冲区对象

#### gl.bindRenderbuffer(target, renderbuffer)

绑定渲染缓冲区对象。如果 renderbuffer 为null，则将已经绑定在target目标上的渲染缓冲区对象解除绑定。参数：

* target：必须为gl.RENDERBUFFER
* renderbuffer: 指定被绑定的渲染缓冲区

#### gl.renderbufferStorage(target, internalformat, width, height)

创建并初始化渲染缓冲区的数据区。作为深度关联对象的渲染缓冲区，其宽度和高度必须与作为颜色关联对象的文理缓冲区一致。参数：

* target:必须为gl.RENDERBUFFER
* internalformat:指定渲染缓冲区中的数据格式。格式包括：
  * gl.DEPTH_COMPONENT16, 表示渲染缓冲区将代替深度缓冲区；
  * gl.STENCIL_INDEX8, 表示渲染缓冲区将替代模板缓冲区；
  * gl.RGBA4, 表示渲染缓冲区将替代颜色缓冲区，表示这4个分量各占据4个比特；
  * gl.RGB5_A1, 表示RGB个占据5个比特而A占据1个比特；
  * gl.RGB565,表示RGB分别占据5、6、5个比特

* width和height:指定渲染缓冲区的宽度和高度以像素为单位



#### gl.createFramebuffer()

创建帧缓冲区对象

#### gl.deleteFramebuffer(framebuffer)

删除帧缓冲区对象

#### gl.bindFramebuffer(target, framebuffer)

绑定帧缓冲区对象。如果framebuffer 为 null，那么已经绑定到target目标上的帧缓冲区对象将被解除绑定。参数：

* target：必须是gl.FRAMEBUFFER
* framebuffer: 被绑定的帧缓冲区对象



#### gl.framebufferTexture2D(target, attachment, textarget, texture, level)

将文理对象关联到帧缓冲区对象。参数：

* target: 必须是gl.FRAMEBUFFER

* attachment: 指定关联的类型。包括：

  * gl.COLOR_ATTACHMENT0, 表示texture是颜色关联对象；这里有个0是因为，在OpenGL中，帧缓冲区可以具有多个颜色关联对象 gl.COLOR_ATTACHMENT0, gl.COLOER_ATTACHMENT1等等，但WebGL中只可以有一个。
  * gl.DEPTH_ATTACHMENT, 表示texture是深度关联对象

* textarget: 同textureImage2D() 函数的第一个参数 gl.TEXTURE_2D 或 gl.TEXTURE_CUBE

* texture: 指定关联的纹理对象

* level: 指定为0 在使用MIPMAP纹理时指定纹理的层级

  

#### gl.framebufferRenderbuffer(target, attachment, renderbuffertarget, renderbuffer)

将渲染缓冲区对象关联到绑定到帧缓冲区对象。参数：

* target:必须是gl.FRAMEBUFFER
* attachment:指定关联的类型。
  * gl.COLOR_ATTACHMENT0,表示renderbuffer是颜色关联对象；
  * gl.DEPTH_ATTACHMENT,表示renderbuffer是深度关联对象；
  * gl.STENCIL_ATTACHMENT,表示renderbuffer是模板关联对象
* renderbuffertarget:必须是gl.RENDERBUFFER
* renderbuffer:指定被关联的渲染缓冲区对象



#### gl.checkFramebufferStatus(target)

检查绑定在target上的帧缓冲区对象的配置状态。参数：

* target:必须为gl.FRAMEBUFFER
* 返回值：0, target不是gl.FRAMEBUFFER。其他包括：
  * gl.FRAMEBUFFER_COMPLETE,帧缓冲区对象正确配置；
  * gl.FRAMEBUFFER_INCPOMPLETE_ATTACHMENT,某一个关联对象为空，或者关联对象不合法；
  * gl.FRAMEBUFFER_INCOMPOLETE_DIMENSIOUS,颜色关联对象和深度关联对象的尺寸不一致；
  * gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT,帧缓冲区尚未关联任何一个关联对象



### 绘制阴影

阴影贴图是一种使用深度纹理来为渲染阴影提供解决方案的多通道计算，需要使用到帧缓冲区对象。

它的关键是，就是用投射光源代替最终视口来观察场景。通过移动视口到光源位置，可以观察到这个位置每个东西都是明亮的，因为从光的角度来看是没有阴影的。

从光源的角度将场景的深度渲染到一张深度缓冲区中，我们可以在场景中获得一张阴影或者无阴影的贴图。

这张纹理就被称为阴影贴图 shadow map，又称深度贴图 depth map，而通过阴影贴图实现阴影的方法就被称为阴影映射 shadow mapping。

帧缓冲区对象工作过程：

1. 光源坐标系下，阴影顶点着色器将图形坐标插值传入片元着色器时，其中的深度值已经写入到深度关联对象中的深度渲染缓冲对象。
2. 在阴影片元着色器中取出深度值z，然后分解保存到gl_FragColor的颜色分量，接着颜色数据会绘制到帧缓冲颜色关联对象中的纹理对象，在这里帧缓冲对象只是用于保存数据，它是离屏渲染，不会绘制到屏幕
3. 当前视点坐标系下，绘制着色器先计算出光源坐标系下的位置，由该位置可直接得出深度值z，xy分量则可从纹理贴图中取出该阴影的深度值z，两深度值比较即可得出坐标是否在阴影中。

```c
// 当光源与照射物间距离变远,z值会增大,而1个分量的8位已经不够存储深度值,所以使用4个分量(rgba) 4字节共32位来存储z值,1个字节8位精度为1/256    
vec4 pack (float depth) {
  const vec4 bitShift = vec4(1.0, 256.0, 256.0 * 256.0, 256.0 * 256.0 * 256.0);
  const vec4 bitMask = vec4(1.0/256.0, 1.0/256.0, 1.0/256.0, 0.0);
  vec4 rgbaDepth = fract(depth * bitShift); //计算每个点的z值 
  rgbaDepth -= rgbaDepth.gbaa * bitMask; // 
  return rgbaDepth;
}
// gl_FragCoord是片元在屏幕下的坐标，即只能是可视范围内的片元
// 将深度值z分段存储到rgba分量
// 阴影片元着色器
void main() {
	gl_FragColor = pack(gl_FragCoord.z);
}

/**
* 释出深度值z
*/
float unpack(const in vec4 rgbaDepth) {
  const vec4 bitShift = vec4(1.0, 1.0/256.0, 1.0/(256.0*256.0), 1.0/(256.0*256.0*256.0));
  return dot(rgbaDepth, bitShift);
}
// pcf消除阴影边缘的锯齿
float pcf(float cosTheta,vec4 v_positionFromLight) {
    float shadows = 0.0;
    float opacity = 0.4;// 基底阴影alpha值
    float texelSize = 1.0/2048.0;// 阴影像素尺寸,值越小阴影越逼真
    vec4 rgbaDepth;
    // 将xyz坐标从齐次坐标区间[-1,1]归一化为纹理使用的[0,1]，xy分量用于查找纹理颜色值rgba，z分量就是在光源坐标系下的深度值; 
    vec3 shadowCoord = (v_positionFromLight.xyz/v_positionFromLight.w)/2.0 + 0.5;
    // 根据光线与表面的夹角计算偏移量,用于消除马赫带
    float bias = 0.005 * tan(acos(cosTheta));
    bias = clamp(bias, 0.0015, 0.01);

    for(float y=-1.5; y <= 1.5; y += 1.0){
        for(float x=-1.5; x <=1.5; x += 1.0){
            rgbaDepth = texture2D(u_shadowMap, shadowCoord.xy + vec2(x,y) * texelSize);
            shadows += step(shadowCoord.z - bias, unpack(rgbaDepth));
        }
    }
    shadows /= 16.0;
    return min(opacity + shadows, 1.0);
    //不使用pcf的方案
    //vec4 rgbaDepth = texture2D(u_shadowMap, shadowCoord.xy);// 获取指定纹理坐标处的像素颜色rgba
    //float depth = unpack(rgbaDepth); // 从纹理颜色值(rgba)解析出阴影深度值z
    //float visibility = (shadowCoord.z > depth + bias) ? 0.5 : 1.0;//大于阴影贴图中的z值,说明在阴影中
}
```



### WebGL调试

WebGL inspector 只能在服务器的页面调试，即不能调试静态html页面比如file:///Users/jeffzhong/develop/shadow_demo.html。

```javascript
//必须开启调试模式true，还不支持webgl2
var gl = canvas.getContext('webgl', true);
```



可能是空格包含其他特殊字符比如\r\n\t，用空格或\t重新替换即可

```javascript
WebGL: INVALID_VALUE: shaderSource: string not ASCII
```



如果要使用导数(dFdx, dFdy, fwidth)，glsl 需要加上以下宏定义

```c
#extension GL_OES_standard_derivatives : enable
```

着色器uniform 不能传bool，int 类型



### drawBuffers

#### webgl2

```js
gl.drawBuffers([gl.NONE, gl.COLOR_ATTACHMENT1]);
```



#### webgl1

Enabling the extension:

```js
var ext = gl.getExtension('WEBGL_draw_buffers');
```

Binding multiple textures (to a `tx[]` array)  to different framebuffer color attachments:

```js
var fb = gl.createFramebuffer();
gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT0_WEBGL, gl.TEXTURE_2D, tx[0], 0);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT1_WEBGL, gl.TEXTURE_2D, tx[1], 0);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT2_WEBGL, gl.TEXTURE_2D, tx[2], 0);
gl.framebufferTexture2D(gl.FRAMEBUFFER, ext.COLOR_ATTACHMENT3_WEBGL, gl.TEXTURE_2D, tx[3], 0);
```

Mapping the color attachments to draw buffer slots that the fragment shader will write to using `gl_FragData`:

```js
ext.drawBuffersWEBGL([
  ext.COLOR_ATTACHMENT0_WEBGL, // gl_FragData[0]
  ext.COLOR_ATTACHMENT1_WEBGL, // gl_FragData[1]
  ext.COLOR_ATTACHMENT2_WEBGL, // gl_FragData[2]
  ext.COLOR_ATTACHMENT3_WEBGL  // gl_FragData[3]
]);
```

Shader code that writes to multiple textures:

```html
<script type="x-shader/x-fragment">
#extension GL_EXT_draw_buffers : require 

precision highp float; 

void main(void) { 
  gl_FragData[0] = vec4(0.25); 
  gl_FragData[1] = vec4(0.5);
  gl_FragData[2] = vec4(0.75); 
  gl_FragData[3] = vec4(1.0);
}
</script>
```



抗锯齿后处理

```c
GLuint msFBO = CreateFBOWithMultiSampledAttachments();
// Then create another FBO with a normal texture color attachment
...
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, screenTexture, 0);
...
while(!glfwWindowShouldClose(window))
{
    ...
    glBindFramebuffer(msFBO);
    ClearFrameBuffer();
    DrawScene();
    // Now resolve multisampled buffer(s) into intermediate FBO
    glBindFramebuffer(GL_READ_FRAMEBUFFER, msFBO);
    glBindFramebuffer(GL_DRAW_FRAMEBUFFER, intermediateFBO);
    glBlitFramebuffer(0, 0, width, height, 0, 0, width, height, GL_COLOR_BUFFER_BIT, GL_NEAREST);
    // Now scene is stored as 2D texture image, so use that image for post-processing
    glBindFramebuffer(GL_FRAMEBUFFER, 0);
    ClearFramebuffer();
    glBindTexture(GL_TEXTURE_2D, screenTexture);
    DrawPostProcessingQuad();  
    ...
}
```
